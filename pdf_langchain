!pip install langchain langchain-community langchain-text-splitters
!pip install faiss-cpu
!pip install sentence-transformers
!pip install pypdf


from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS


# loadingPDF
loader = PyPDFLoader("dosya.pdf")
documents = loader.load()

print(f" PDF yüklendi, toplam {len(documents)} sayfa bulundu.")


# Metin parçalama
text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = text_splitter.split_documents(documents)

# Embedding model
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

# FAISS index oluşturma
db = FAISS.from_documents(docs, embeddings)


# Search
query = "machine learning"
results = db.similarity_search(query, k=5)

print("\n Semantic Search Sonuçları:")
for r in results:
    print("-", r.page_content[:200], "...")  #ilk 200 karakter
